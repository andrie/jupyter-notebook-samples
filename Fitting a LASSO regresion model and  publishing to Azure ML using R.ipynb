{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a LASSO regresion model and  publishing to Azure ML using R\n",
    "\n",
    "## Introduction\n",
    "### About the method\n",
    "LASSO, which stands for Least Absolute Shrinkage and Selection Operator, is one of the model complexity control techniques like variable selection and ridge regression. In this notebook we'll demonstrate how to use the *glmnet* package for LASSO regression. For more information about LASSO you can refer to the [LASSO Page][lasso link].\n",
    "\n",
    "[lasso link]: http://statweb.stanford.edu/~tibs/lasso.html\n",
    "\n",
    "### Target audience\n",
    "This notebook is targeted toward data scientists who understand linear regression and want to find out how to fit LASSO regression in R. An operationalization step is also included to show how you can deploy in Azure a web service based on the selected model. \n",
    "\n",
    "## Data\n",
    "In this example, we'll use the housing data from the R package `MASS`. There are 506 rows and 14 columns in the dataset. Available information includes median home price, average number of rooms per dwelling, crime rate by town, etc. More information about this dataset can be found at [UCI][uci link] or by typing `help(Boston)` in an R terminal.\n",
    "\n",
    "[uci link]: https://archive.ics.uci.edu/ml/datasets/Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "?Boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "For illustration purposes, we'll use \"medv\" - median home price - as the response variable and the remaining variables as predictors.\n",
    "\n",
    "The first step in fitting LASSO regression is to determine the value of tuning parameter λ which controls the overall strength of the penalty. Here we'll use cross-validation to choose the λ that gives the least validation error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to make results replicable\n",
    "set.seed(123)\n",
    "\n",
    "# load libraries\n",
    "if(!require(\"glmnet\", quietly = TRUE)) install.packages(\"glmnet\")\n",
    "library(glmnet) # to fit a LASSO model\n",
    "library(MASS) # to use the Boston dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define response variable and predictor variables\n",
    "response_column <- which(colnames(Boston) %in% c(\"medv\"))\n",
    "train_X <- data.matrix(Boston[, -response_column])\n",
    "train_y <- Boston[,response_column]\n",
    "\n",
    "# use cv.glmnet with 10-fold cross-validation to pick lambda\n",
    "model1 <- cv.glmnet(x = train_X, \n",
    "                    y = train_y, \n",
    "                    alpha = 1, \n",
    "                    nfolds = 10, \n",
    "                    family = \"gaussian\", \n",
    "                    type.measure = \"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "summary(model1)\n",
    "options(repr.plot.width = 5, repr.plot.height = 5)\n",
    "plot(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above:\n",
    "\n",
    "* The red dotted line shows the cross-validation error and the error bars show the uppper and lower standard deviation.\n",
    "* The dotted vertical line to the left is for the optimal λ that gives minimum mean cross-validation error.\n",
    "* The vertical line to the right is for the λ where cross-validation error falls within one standard error of the minimum error.\n",
    "* The number of nonzero coefficients for different λ is shown along the axis at the top. The values for λ and associated coefficients are printed below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda that gives minimum mean cross-validated error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "round(model1$lambda.min, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Largest lambda with mean cross-validated error within 1 standard error of the minimum error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "round(model1$lambda.1se, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficients based on lambda that gives minimum mean cross-validated error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "coef(model1, s = \"lambda.min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the model selected by cv.glmnet() can be used for making predictions, we also want to better understand how the values of λ impact the estimated coefficients. Such information can be produced by the glmnet() function. In the plot that's generated below, it can be observed that the coefficients shrink toward zero as the value of λ increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model2 <- glmnet(x = train_X, \n",
    "                 y = train_y, \n",
    "                 alpha = 1, \n",
    "                 family = \"gaussian\")\n",
    "\n",
    "# identify variable names\n",
    "vn = colnames(train_X)\n",
    "vid <- as.character(seq(1, length(vn)))\n",
    "\n",
    "# check and exclude the variables with coefficient value 0 \n",
    "vnat = coef(model2)\n",
    "vnat_f <- vnat[-1, ncol(vnat)] \n",
    "vid <- vid[vnat_f != 0]\n",
    "vn <- vn[vnat_f != 0]\n",
    "\n",
    "#define the legend description, line type, and line color\n",
    "nvars <- length(vn)\n",
    "legend_desc <- paste(vid, vn, sep=\": \")\n",
    "legend_desc\n",
    "mylty <- rep(1,nvars)\n",
    "mycl <- seq(1,nvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Varying lambda\n",
    "\n",
    "By increasing the value of lambda, the regression parameters are increasingly penalised, and thus move closer to zero.\n",
    "\n",
    "In the lambda plot below, you can see how the coefficients gradually decrease in value as lambda increaes. This has a particularly high impact on variable 5 (nox, nitrogen oxides concentration (parts per 10 million)).\n",
    "\n",
    "This shows the value of LASSO regression: the algorithm deals very well with problematic predictors, for example situations where the predictors are higly correlated with one another (multi-collinearity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "options(repr.plot.width = 6, repr.plot.height = 6)\n",
    "plot(model2, xvar = \"lambda\", label = TRUE, col = mycl, xlim = c(-5.5, 2))\n",
    "legend(-0.5,-2, legend_desc, lty = mylty, col = mycl, cex = 0.8) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients from this model with the optimal λ are also printed below. As we would expect, they are the same as those from using cv.glmnet()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coef(model2, s = model1$lambda.min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make predictions, you can use either of the two models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_new <- data.matrix(train_X[, -response_column])\n",
    "pred1 <- predict(model1, newx = x_new, s = \"lambda.min\")\n",
    "pred2 <- predict(model2, newx = x_new, s = model1$lambda.min)\n",
    "\n",
    "head(\n",
    "    data.frame(actual = Boston$medv, model1 = as.vector(pred1), model2 = as.vector(pred2))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web service\n",
    "### Deploy a web service\n",
    "With the developed model, we can deploy a web service on Azure so that others can use it to make predictions. The \"AzureML\" package will be used for this purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define predict function\n",
    "mypredict <- function(newdata){\n",
    "    if(\"medv\" %in% names(newdata)) {\n",
    "        w <- match(\"medv\", names(newdata))\n",
    "        newdata <- newdata[, -w]\n",
    "        }\n",
    "  require(glmnet)\n",
    "  newdata <- data.matrix(newdata) # the prediction data need to be a matrix for glmnet\n",
    "  predict(model2, newx = newdata, s = model1$lambda.min)\n",
    "}\n",
    "\n",
    "# test the prediction function\n",
    "newdata <- Boston[1:10, ]\n",
    "mypredict(newdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the library\n",
    "library(AzureML)\n",
    "\n",
    "# workspace information\n",
    "ws <- workspace()\n",
    "\n",
    "# deploy the service\n",
    "ep <- publishWebService(ws = ws, fun = mypredict, \n",
    "                        name = \"LASSOPrediction\", \n",
    "                        inputSchema = newdata, \n",
    "                        outputSchema = list(ans = \"numeric\"))\n",
    "str(ep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consume a web service\n",
    "With information about the workspace and and service ID, we can consume the web service with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newdata <- Boston[1:10, ]\n",
    "pred <- consume(ep, newdata)$ans\n",
    "data.frame(actual = newdata$medv, prediction = pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Using the `Boston` housing dataset, we demonstrated how to carry out LASSO regression analysis. We started the analysis by determining the optimal value of the tuning parameter λ using cross-validation. Then we examined the impact of λ on the coefficient estimates. A web service was deployed based on the selected model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "Created by a Microsoft Employee.  \n",
    "Copyright (C) Microsoft. All Rights Reserved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
